from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
import pandas as pd
import os
from dotenv import load_dotenv


load_dotenv()

# Fonction de cr√©ation des Vector Stores
def create_faiss_index(input_json_path, output_faiss_path):
    # Charger les donn√©es
    df = pd.read_json(input_json_path)

    # Extraire les contenus des documents
    documents = df['content'].tolist()

    # Cr√©er les embeddings avec OpenAI
    embeddings = OpenAIEmbeddings()

    # Cr√©er le vectorstore FAISS
    vectorstore = FAISS.from_texts(documents, embeddings)

    # Sauvegarder le vectorstore localement
    vectorstore.save_local(output_faiss_path)

    print(f"‚úÖ FAISS Vector Store cr√©√© et sauvegard√© : {output_faiss_path}")


# Cr√©er les dossiers pour sauvegarder les vecteurs si n√©cessaire
os.makedirs('vectors/programmes_faiss', exist_ok=True)
os.makedirs('vectors/pratiques_faiss', exist_ok=True)
os.makedirs('vectors/etudes_faiss', exist_ok=True)

# Chemins des fichiers JSON d'entr√©e
json_paths = [
    ("data/programmes.json", 'vectors/programmes_faiss'),
    ("data/pratiques.json", 'vectors/pratiques_faiss'),
    ("data/etudes.json", 'vectors/etudes_faiss')
]

# Cr√©ation des Vector Stores pour chaque corpus
for input_json, output_faiss in json_paths:
    create_faiss_index(input_json, output_faiss)

print("üéâ Tous les Vector Stores FAISS ont √©t√© g√©n√©r√©s avec succ√®s.")