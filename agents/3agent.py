from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.agents import AgentExecutor, create_react_agent
from langchain import hub
from langchain.tools import Tool
from langchain_core.prompts import PromptTemplate

load_dotenv()

llm = ChatOpenAI(model="gpt-4o", temperature=0.3)

def load_retriever(vector_path):
    embeddings = OpenAIEmbeddings()
    vectorstore = FAISS.load_local(
        vector_path, 
        embeddings,
        allow_dangerous_deserialization=True
    )
    return vectorstore.as_retriever()

def create_qa_tool(name, vector_path, description):
    """Cr√©e un outil bas√© sur RetrievalQA pour un vector store sp√©cifique."""
    retriever = load_retriever(vector_path)
    # Cha√Æne simple pour r√©pondre aux questions bas√©es sur les documents r√©cup√©r√©s
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        retriever=retriever,
        chain_type="stuff", # M√©thode simple pour combiner les documents
        return_source_documents=False
    )
    return Tool(
        name=name,
        func=qa_chain.invoke, # La fonction de l'outil appelle la cha√Æne QA
        description=description
    )

# --- 2. Cr√©ation des Outils Sp√©cifiques ---

try:
    tool_programmes = create_qa_tool(
        name="FormationProgrammeTool",
        vector_path="../vectors/programmes_faiss",
        description="Utile pour r√©pondre aux questions sur les programmes de formation disponibles."
    )

    tool_pratiques = create_qa_tool(
        name="MeilleuresPratiquesTool",
        vector_path="../vectors/pratiques_faiss",
        description="Utile pour r√©pondre aux questions sur les meilleures pratiques, conseils et m√©thodes √©prouv√©es en entreprise."
    )

    tool_etudes = create_qa_tool(
        name="EtudesDeCasTool",
        vector_path="../vectors/etudes_faiss",
        description="Utile pour trouver des exemples concrets, des illustrations ou des retours d'exp√©rience √† partir d'√©tudes de cas."
    )
except FileNotFoundError as e:
    print(f"Erreur: {e}")
    print("Veuillez v√©rifier les chemins des fichiers FAISS ('vectors/...') et que les index existent.")
    exit()

# --- 3. Cr√©ation des Trois Agents Sp√©cialis√©s ---
# Chaque agent n'a acc√®s qu'√† son propre outil.
# On utilise ici un agent React simple qui est bon pour utiliser des outils.

react_prompt = hub.pull("hwchase17/react")

agent_programmes = AgentExecutor(
    agent=create_react_agent(llm, [tool_programmes], react_prompt),
    tools=[tool_programmes],
    verbose=True,
    handle_parsing_errors=True,
    max_iterations=3
)

agent_pratiques = AgentExecutor(
    agent=create_react_agent(llm, [tool_pratiques], react_prompt),
    tools=[tool_pratiques],
    verbose=True,
    handle_parsing_errors=True,
     max_iterations=3
)

agent_etudes = AgentExecutor(
    agent=create_react_agent(llm, [tool_etudes], react_prompt),
    tools=[tool_etudes],
    verbose=True,
    handle_parsing_errors=True,
    max_iterations=3
)

# --- 4. Fonction d'Orchestration et de Fusion ---

fusion_prompt_template = """
Vous √™tes un assistant expert en synth√®se d'informations.
L'utilisateur a pos√© la question suivante : "{question}"

Vous avez re√ßu des informations potentiellement pertinentes de trois sources sp√©cialis√©es :

1. Informations sur les Programmes de Formation :
{reponse_programmes}

2. Informations sur les Meilleures Pratiques :
{reponse_pratiques}

3. Informations provenant d'√âtudes de Cas :
{reponse_etudes}

Votre t√¢che est de synth√©tiser ces informations pour fournir une r√©ponse globale, coh√©rente et utile √† la question initiale de l'utilisateur. Ignorez les informations non pertinentes provenant des sources. Si une source ne fournit pas d'information utile pour r√©pondre √† la question, ne l'inventez pas. Basez votre r√©ponse uniquement sur les √©l√©ments fournis.

R√©ponse Synth√©tis√©e :
"""

fusion_prompt = PromptTemplate(
    input_variables=["question", "reponse_programmes", "reponse_pratiques", "reponse_etudes"],
    template=fusion_prompt_template,
)

# LLM pour la fusion
fusion_llm = ChatOpenAI(model="gpt-4o", temperature=0.5)

def orchestrate_and_fuse(question: str) -> str:
    print(f"\n--- Orchestration pour la question : '{question}' ---")

    # Appeler chaque agent sp√©cialis√©
    try:
        print("\n[Orchestrateur] Interrogation de l'agent Programmes...")
        response_prog_agent = agent_programmes.invoke({"input": question})
        reponse_programmes = response_prog_agent['output']
        print(f"[Agent Programmes] R√©ponse re√ßue.")
    except Exception as e:
        print(f"[Agent Programmes] Erreur : {e}")
        reponse_programmes = "Erreur lors de la r√©cup√©ration des informations sur les programmes."

    try:
        print("\n[Orchestrateur] Interrogation de l'agent Meilleures Pratiques...")
        response_prat_agent = agent_pratiques.invoke({"input": question})
        reponse_pratiques = response_prat_agent['output']
        print(f"[Agent Pratiques] R√©ponse re√ßue.")
    except Exception as e:
        print(f"[Agent Pratiques] Erreur : {e}")
        reponse_pratiques = "Erreur lors de la r√©cup√©ration des informations sur les meilleures pratiques."

    try:
        print("\n[Orchestrateur] Interrogation de l'agent √âtudes de Cas...")
        response_etu_agent = agent_etudes.invoke({"input": question})
        reponse_etudes = response_etu_agent['output']
        print(f"[Agent Etudes] R√©ponse re√ßue.")
    except Exception as e:
        print(f"[Agent Etudes] Erreur : {e}")
        reponse_etudes = "Erreur lors de la r√©cup√©ration des informations des √©tudes de cas."

    # Fusionner les r√©ponses
    print("\n[Orchestrateur] Fusion des r√©ponses...")
    formatted_prompt = fusion_prompt.format(
        question=question,
        reponse_programmes=reponse_programmes,
        reponse_pratiques=reponse_pratiques,
        reponse_etudes=reponse_etudes
    )

    final_response = fusion_llm.invoke(formatted_prompt)
    print("[Orchestrateur] Fusion termin√©e.")

    return final_response.content


if __name__ == "__main__":
    question_test = "Quelles formations et bonnes pratiques sont recommand√©es pour am√©liorer le leadership, avec des exemples concrets ?"
    print(f"üßë‚Äçüíª Question : {question_test}")
    reponse_finale = orchestrate_and_fuse(question_test)
    print("\n==================== R√âPONSE FINALE ====================")
    print(f"ü§ñ R√©ponse : {reponse_finale}")
    print("========================================================")

    question_test_2 = "Donne-moi juste la liste des programmes de formation sur la gestion de projet."
    print(f"\nüßë‚Äçüíª Question : {question_test_2}")
    reponse_finale_2 = orchestrate_and_fuse(question_test_2)
    print("\n==================== R√âPONSE FINALE 2 ====================")
    print(f"ü§ñ R√©ponse : {reponse_finale_2}")
    print("==========================================================")